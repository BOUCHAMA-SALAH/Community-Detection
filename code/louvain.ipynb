{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "### Using Louvain algorithem to detect communities in graphs "}, {"cell_type": "code", "execution_count": 40, "metadata": {}, "outputs": [], "source": "# our implementation of louvain method takes alot of time \n# we use the method implemented in python_louvain instead\n# if you want to test the method, uncomment the following\n#from louvain import *"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "# reading graph edges from bigQuery tables \nfrom google.cloud import bigquery\nfrom scipy.sparse import csr_matrix\nimport numpy as np \nfrom google.cloud import storage\nfrom google.cloud import bigquery\nfrom pyspark.sql import *\nimport pandas as pd\nfrom scipy.io import mmwrite\nimport networkx as nx\nfrom networkx.algorithms import community\nimport community as community_louvain\nimport time \nspark = SparkSession.builder \\\n  .appName('data-preparation')\\\n  .config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar') \\\n  .getOrCreate()"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "-----------------------------------\n##### BigQuery table infos :\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 396160 entries, 0 to 396159\nData columns (total 3 columns):\n #   Column  Non-Null Count   Dtype\n---  ------  --------------   -----\n 0   id      396160 non-null  int64\n 1   fromId  396160 non-null  int64\n 2   toId    396160 non-null  int64\ndtypes: int64(3)\nmemory usage: 9.1 MB\nNone\n##### number of nodes 18771 in dataset : CA-AstroPh\n##### time elepsed 45.3023 seconds \n##### number of partitions is 325 in dataset : CA-AstroPh\n-----------------------------------\n##### BigQuery table infos :\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28980 entries, 0 to 28979\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype\n---  ------  --------------  -----\n 0   id      28980 non-null  int64\n 1   fromId  28980 non-null  int64\n 2   toId    28980 non-null  int64\ndtypes: int64(3)\nmemory usage: 679.3 KB\nNone\n##### number of nodes 5241 in dataset : CA-GrQc\n##### time elepsed 3.1854 seconds \n##### number of partitions is 392 in dataset : CA-GrQc\n-----------------------------------\n##### BigQuery table infos :\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 237010 entries, 0 to 237009\nData columns (total 3 columns):\n #   Column  Non-Null Count   Dtype\n---  ------  --------------   -----\n 0   id      237010 non-null  int64\n 1   fromId  237010 non-null  int64\n 2   toId    237010 non-null  int64\ndtypes: int64(3)\nmemory usage: 5.4 MB\nNone\n##### number of nodes 12007 in dataset : CA-HepPh\n##### time elepsed 14.0944 seconds \n##### number of partitions is 314 in dataset : CA-HepPh\n-----------------------------------\n##### BigQuery table infos :\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 51971 entries, 0 to 51970\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype\n---  ------  --------------  -----\n 0   id      51971 non-null  int64\n 1   fromId  51971 non-null  int64\n 2   toId    51971 non-null  int64\ndtypes: int64(3)\nmemory usage: 1.2 MB\nNone\n##### number of nodes 9876 in dataset : CA-HepTh\n##### time elepsed 7.4150 seconds \n##### number of partitions is 478 in dataset : CA-HepTh\n"}], "source": "files = ['CA-AstroPh', 'CA-GrQc',  'CA-HepPh', 'CA-HepTh' ]\n# the bucket where we store the edges of each dataset in cloud storage \nBUCKET_NAME = 'rplace-bucket'\n# project name in GCP \nproject_name = \"bigdata-project-346922\"\ndataset = \"collaboration_data\"\n\npartitions = []\nelepses = []\nclient = bigquery.Client()\n\nfor file in files: \n    table_id = project_name + '.' + dataset + '.' + file\n    # getting tables from BigQuery \n    dataframe = client.list_rows(table_id).to_dataframe(create_bqstorage_client=True)\n    print(\"-----------------------------------\")\n    print(\"##### BigQuery table infos :\")\n    print(dataframe.info())\n    # sparse matrix creation for each graph \n    rows = list(dataframe['fromId'])\n    cols = list(dataframe['toId'])\n    data = [1 for i in range(len(cols))]\n    # we use identfiersList to map all nodes identifiers \n    # to the interval [0 - (nodes -1)]\n    # in order to keep the sparse matrix small enough \n    \n    identifiersList = [i for i in set(cols + rows)]\n    identifiersList.sort()\n    dic = dict()\n    node = 0\n    for i in identifiersList:\n        dic[i] = node\n        node+=1\n    for k in range(len(cols)): \n        cols[k] = dic[cols[k]]\n        rows[k] = dic[rows[k]]\n    nodes = max(cols + rows)\n    print(f\"##### number of nodes {nodes} in dataset : {file}\")\n    m = csr_matrix((data, (rows, cols)), shape=(nodes+1, nodes+1), dtype=np.uint16)\n    # m is a sparse matrix for adjecency matrix, we create then a networkx graph g \n    g = nx.from_scipy_sparse_matrix(m)\n    start = time.time()\n    p = community_louvain.best_partition(g)\n    elepse = time.time() - start\n    elepses.append(elepse)\n    partitions.append(p)\n    print(\"##### time elepsed {:.4f} seconds \".format(elepse))\n    print(\"##### number of partitions is {0} in dataset : {1}\".format( len(set(p.values())), file) ) "}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": "# Saving results in files \ni = 0\nfor file in files : \n    with open(\"louvain_node_to_community.\" + file, \"w\") as f:\n        for n,c in partitions[i].items():\n            f.write(str(n) + \":\" + str(c)+\"\\n\")\n        f.write(\"Time_of_execution:{}\".format(elepses[i]))\n    i+=1\n"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Copying file://./louvain_node_to_community.CA-AstroPh [Content-Type=application/octet-stream]...\nCopying file://./louvain_node_to_community.CA-GrQc [Content-Type=application/octet-stream]...\nCopying file://./louvain_node_to_community.CA-HepPh [Content-Type=application/octet-stream]...\nCopying file://./louvain_node_to_community.CA-HepTh [Content-Type=application/octet-stream]...\n/ [4/4 files][356.6 KiB/356.6 KiB] 100% Done                                    \nOperation completed over 4 objects/356.6 KiB.                                    \n"}], "source": "# copy results files in our working cloud storage bucket \n# this step is optional if we work in local machine\n!gsutil -m cp ./louvain_node_to_community.CA* gs://rplace-bucket/results"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 2}