{"cells": [{"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Requirement already satisfied: node2vec in /opt/conda/anaconda/lib/python3.7/site-packages (0.4.3)\nRequirement already satisfied: networkx in /opt/conda/anaconda/lib/python3.7/site-packages (from node2vec) (2.6.3)\nRequirement already satisfied: tqdm in /opt/conda/anaconda/lib/python3.7/site-packages (from node2vec) (4.64.0)\nRequirement already satisfied: gensim in /opt/conda/anaconda/lib/python3.7/site-packages (from node2vec) (4.1.2)\nRequirement already satisfied: numpy in /opt/conda/anaconda/lib/python3.7/site-packages (from node2vec) (1.17.2)\nRequirement already satisfied: joblib>=0.13.2 in /opt/conda/anaconda/lib/python3.7/site-packages (from node2vec) (0.13.2)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from gensim->node2vec) (5.2.1)\nRequirement already satisfied: scipy>=0.18.1 in /opt/conda/anaconda/lib/python3.7/site-packages (from gensim->node2vec) (1.3.1)\n"}], "source": "!pip install node2vec"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": "# reading graph edges from bigQuery tables \nfrom google.cloud import bigquery\nfrom scipy.sparse import csr_matrix\nimport numpy as np \nfrom google.cloud import storage\nfrom google.cloud import bigquery\nfrom pyspark.sql import *\nimport pandas as pd\nimport networkx as nx\nimport time \nfrom node2vec import *\n\nspark = SparkSession.builder \\\n  .appName('data-preparation')\\\n  .config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar') \\\n  .getOrCreate()"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "##### number of nodes 18771 in dataset : CA-AstroPh\n"}, {"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "5b97e338da174c6da51a57784475a1c1", "version_major": 2, "version_minor": 0}, "text/plain": "Computing transition probabilities:   0%|          | 0/18772 [00:00<?, ?it/s]"}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "All random walks generated for graph CA-AstroPh\nAll embeddings generated for graph CA-AstroPh\n"}, {"ename": "ValueError", "evalue": "Format specifier missing precision", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m<ipython-input-14-543164ea999f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0melepse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All embeddings generated for graph {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time elepsed {:4.f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melepse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mEMBEDDING_FILENAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gs://\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBUCKET_NAME\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"./embeddings/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"embedding.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDING_FILENAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mValueError\u001b[0m: Format specifier missing precision"]}], "source": "files = ['CA-AstroPh', 'CA-GrQc',  'CA-HepPh', 'CA-HepTh' ]\n# the bucket where we store the edges of each dataset in cloud storage \nBUCKET_NAME = 'rplace-bucket'\n# project name in GCP \nproject_name = \"bigdata-project-346922\"\ndataset = \"collaboration_data\"\n\npartitions = []\nelepses = []\nclient = bigquery.Client()\nfor file in files: \n    table_id = project_name + '.' + dataset + '.' + file\n    # getting tables from BigQuery \n    dataframe = client.list_rows(table_id).to_dataframe(create_bqstorage_client=True)\n    # sparse matrix creation for each graph \n    rows = list(dataframe['fromId'])\n    cols = list(dataframe['toId'])\n    data = [1 for i in range(len(cols))]\n    # we use identfiersList to map all nodes identifiers \n    # to the interval [0 - (nodes -1)]\n    # in order to keep the sparse matrix small enough \n    identifiersList = [i for i in set(cols + rows)]\n    identifiersList.sort()\n    dic = dict()\n    node = 0\n    for i in identifiersList:\n        dic[i] = node\n        node+=1\n    for k in range(len(cols)): \n        cols[k] = dic[cols[k]]\n        rows[k] = dic[rows[k]]\n    nodes = max(cols + rows)\n    print(f\"##### number of nodes {nodes} in dataset : {file}\")\n    m = csr_matrix((data, (rows, cols)), shape=(nodes+1, nodes+1), dtype=np.uint16)\n    # m is a sparse matrix for adjecency matrix, we create then a networkx graph g \n    g = nx.from_scipy_sparse_matrix(m)\n    start = time.time()\n    node2vec = Node2Vec(g,dimensions=30, walk_length=32, num_walks=10,p=10, q=0.1,  workers= 8)\n    print(\"All random walks generated for graph {}\".format(file)) \n    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n    elepse = time.time() - start\n    print(\"All embeddings generated for graph {}\".format(file))\n    print(\"time elepsed {}\".format(elepse))\n    EMBEDDING_FILENAME = \"gs://\"+BUCKET_NAME+\"./embeddings/\" + \"embedding.\" + file\n    model.wv.save_word2vec_format(EMBEDDING_FILENAME)\n    elepses.append(elepse) "}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "i = 0\nwith open(\"generating_time\", \"w\") as f: \n    for file in files:\n        f.write(\"graph : {0} - time: {1}\".format(file, elepses[i]))\n        i+= 1 "}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 2}